\input{chpreamble}
  \chapter{Fourier Inversion}
  \label{ch:fourier}

    Consider the function
    \begin{align*}
      \psi:\R\times\R\longrightarrow\C\\
      \psi(x,\xi) = e^{2\pi i \xi x} \text{.}
    \end{align*}
    As $x$ varies for a fixed $\xi$, $\psi$ is a complex sinusoidal oscillation with frequency $\xi$\footnotemark---a ``pure tone.''
    \footnotetext{
      We think of $x$ as a \emph{physical} parameter (position), while $\xi$ is a \emph{frequency} parameter.
      Some confusion comes from the fact that $x$ and $\xi$ are both real numbers; we track the distinction because Fourier analysis generally occurs in cases where physical and frequency space are distinct.
      In fact, much of this chapter extends to having $\R^n$ as the physical space with little work, which further motivates clear notation of physical variables.
    }
    Just as interesting sounds are combinations of different frequencies, we can view functions as being built from linear combinations these oscillations.

    Given a function $f:\R\rightarrow\C$, we can measure how much it ``matches'' the behavior of some frequency-$\xi$ oscillation by integrating the two against each other.
    We think of this integration as taking an inner product---measuring the amount to which two vectors parallel one another.
    Because any two oscillations of different frequency have inner product 0 we think of them as \emph{orthogonal}, meaning that any frequency's inner product with $f$ is independent of any other's.
    We hope that by knowing how well $f$ matches each frequency, we're able to exactly rebuild $f$.
    This process of translating a function from physical to frequency space, and (hopefully) back, is the subject matter of \emph{Fourier analysis}.

    \begin{defn}
      The \emph{frequency spectrum} or \emph{Fourier transform} of $f$ is a new function denoted $\F f$, taking a real parameter $\xi$.
      The value $\F f(\xi)$ can be thought of as an inner product of $f$ with a frequency-$\xi$ oscillation:
      \begin{align*}
        \F f&:\R\longrightarrow\C\\
        \F f(\xi) &= \int_{x\in\R} f(x)\overline\psi(x,\xi)\,dx \text{.}
      \end{align*}
      Given such a frequency spectrum, we can also combine together oscillations to create a new function with the \emph{inverse Fourier transform}:
      \begin{align*}
        \F^{-1}g&:\R\longrightarrow\C\\
        \F^{-1}g(x) &= \int_{\xi\in\R} g(\xi)\psi(x,\xi)\,d\xi \text{.}
      \end{align*}
    \end{defn}

    We hope that $\F^{-1}$ does in fact invert $\F$, so that $\F^{-1}\F f = f$ for any function $f$---that is, applying the inverse Fourier transform to the frequency spectrum of $f$ gives us back $f$.
    However, this claim is difficult to make because the integrals are not always defined.
    For example, $\F1(0)=\int_{-\infty}^\infty1$ is clearly divergent.
    In order to talk meaningfully about Fourier inversion we'll need an environment in which Fourier transforms are sensible, and so we need to limit our space of functions so that the Fourier transform works nicely.
    It is worth noting at this point that $\F^{-1}g(x) = \F g(-x)$, and so any properties of the Fourier transform extend to the inverse Fourier transform, meaning we only need consider the former.

    \section{Properties of the Fourier Transform}
      Before we develop a space of functions on which the Fourier transform is well-behaved, it is helpful to have an idea of how the Fourier transform acts.
      First, for any $x\in\R$ define:
      \begin{itemize}
        \item the frequency-$x$ oscillation $\psi_x$:
          \begin{align*}
            \psi_x:\R\rightarrow\C,\ \psi_x(\xi) = \psi(x,\xi) = e^{2\pi i x \xi}
          \end{align*}
        \item the translation operator $T_x$ on functions $f:\R\rightarrow\C$:
          \begin{align*}
            (T_xf)(y) = f(x+y)
          \end{align*}
      \end{itemize}
      The following lemma gives identities that can be computed directly from definition.
      \begin{lemma}
        \label{lemma:fourprops}
        Let $a,b\in\R$ and take $f,g:\R\rightarrow\C$.
        Then, working purely formally (that is, assuming all integrals are well behaved):
        \begin{align}
          \F(af + bg) &= a\F f + b\F g\\
          \label{eq:tsltispsi}
            T_x\F^{-1}f &= \F^{-1}(\psi_xf)\\
          \label{eq:tsltispsi2}
          \psi_x\F f &= \F(T_xf)\\
          \label{eq:xisdiff}
            \F(xf) &= -\frac{1}{2\pi i}(\F f)'\\
          \label{eq:xisdiff2}
            \F(f') &= -2\pi i\xi\F f
        \end{align}
        \begin{proof}[Proof of \cref{eq:tsltispsi}]
          \begin{align*}
            (T_x\F^{-1}f)(y) &= (\F^{-1}f)(x+y)\\
            &= \int_{\xi\in\R}f(\xi)e^{2\pi i(x+y)\xi}\,d\xi\\
            &= \int_{\xi\in\R}f(\xi)\psi_x(\xi)\psi(y,\xi)\,d\xi\\
            &= \F^{-1}(\psi_xf)(y)
          \end{align*}
        \end{proof}
        \begin{proof}[Proof of \cref{eq:xisdiff}]
          \begin{align*}
            (\F f)'(\xi) &= \frac{d}{d\xi}\int_{x\in\R} f(x)e^{-2\pi i x\xi}\,dx\\
            &= -2\pi i \int_{x\in\R} xf(x)e^{2\pi i x\xi}\,dx\\
            &= -2\pi i\F(xf)(\xi)
          \end{align*}
        \end{proof}
      \end{lemma}
      This result demonstrates the key properties of the Fourier transform:
      \begin{itemize}
        \item \F is linear;
        \item \F exchanges multiplication by an oscillation and translation;
        \item \F exchanges multiplication by $x$ and differentiation.
      \end{itemize}
      These properties make the Fourier transform useful for solving real-world problems.
      \begin{example}[The heat equation]
        \label{ex:heateq}
        Consider a long metal wire whose temperature at time $t=0$ is given by a function $f(x)$.
        We would like to describe the temperature distribution on the wire as time passes.

        Write the temperature of a point $x$ on the wire at time $t>0$ as $u(x,t)$.
        The \emph{heat equation} from physics tells us that
        \begin{align*}
          \frac{\partial}{\partial t}u(x,t) &= \alpha\frac{\partial^2}{\partial x^2}u(x,t)
        \end{align*}
        for some $\alpha$ in \R that depends on the properties of our wire. 
        Noting that the Fourier transform exchanges differentiation and multiplication by a variable, we take the Fourier transform of our differential equation with respect to the spatial variable ($x$):
        \begin{align*}
          \F_x\left(\frac{\partial}{\partial t}u(x,t)\right) &= \F_x\left(\alpha\frac{\partial^2}{\partial x^2}u(x,t)\right)\\
          \frac{\partial}{\partial t}\F_xu(\xi,t) &= -k\xi^2\F_xu(\xi,t)
        \end{align*}
        passing the $t$ derivative through the $x$ integral and folding $\alpha$ and the constants of \cref{eq:xisdiff2} into~$k$.

        As we hoped, these transformations have made the differential equation easier to solve, by replacing $x$ derivatives with multiples of $\xi$.
        Solving yields
        \begin{align*}
          \F_xu(\xi,t) &= c(\xi)e^{-k\xi^2t}
        \end{align*}
        for some function $c$.
        The initial condition $u(x,0)=f(x)$ is transformed to $\F_xu(\xi,0) = \F_x f(\xi)$, so $c(\xi)=\F_x f(\xi)$.

        Having solved the differential equation in frequency space, we use the inverse Fourier transform to recover the solution in physical space:
        \begin{align}
          \notag u(x,t) &= \F^{-1}_\xi(e^{-k\xi^2t}\F_x f(\xi))\\
          \notag &= \int_{\xi\in\R} \F_x f(\xi)e^{-k\xi^2t}\psi(x,\xi)\,d\xi\\
          \notag &= \int_{\xi\in\R} \int_{y\in\R} f(y)\psi(y,\xi)\,dy\,e^{-k\xi^2t}\psi(x,\xi)\,d\xi\\
          \notag &= \int_{y\in\R} f(y) \int_{\xi\in\R} e^{-k\xi^2t}\psi(x+y,\xi)\,d\xi\,dy\\
          \label{eq:heatsoln} &= \frac{1}{\sqrt{4\pi kt}}\int_{y\in\R} f(y)e^{-(x-y)^2/4kt}\,dy
        \end{align}
        which is verifiably a solution to the heat equation.
        An example of this solution is shown in \cref{fig:heateq}.

        \begin{figure}[p]
          \begin{center}
            \begin{sagesilent}
              x,y,t=var('x,y,t')
              gamma(x,t) = e^(-(x^2)/t)
              f(x)=(sgn(x)*sgn(1-x))
              assume(t>0)
              u(x,t) = (1/sqrt(t))*(integral(f(y)*gamma(x-y,t),y,-Infinity,0)+integral(f(y)*gamma(x-y,t),y,0,1)+integral(f(y)*gamma(x-y,t),y,1,Infinity))
            \end{sagesilent}
            \sageplot[width=\figwidth]{reduce(lambda x,y: x+y,[plot(u(x,t),x,(-1,2),color=c,legend_label='$t='+str(t)+'$',axes=false,figsize=[6,4]) for t,c in [(1/1000,(0,0,0)), (1/32,(.1,.1,.1)), (1/8,(.3,.3,.3)), (1/4,(.4,.4,.4)), (1/2,(.5,.5,.5)), (1,(.6,.6,.6)), (2,(.7,.7,.7))]])}
          \end{center}
          \caption{An example solution to the heat equation for a square pulse of heat, calculated from the function $u(x,t)$ derived in \cref{ex:heateq}.}
          \label{fig:heateq}
        \end{figure}
      \end{example}
      
      The solution $u(x,t)$ is an example of convolution---roughly, the averaging of one function by another.
      For some fixed $t>0$ we have
      \begin{align*}
        u(x,t)= C_1\cdot\int_{y\in\R}f(y)e^{-(x-y)^2/C_2}\,dy \text{.}
      \end{align*}
      At any $x$, the value of $u$ is determined by integrating $f(y)$ against a Gaussian\footnote{Recall the Gaussian function $e^{-x^2}$ is a small pulse with integral $\sqrt\pi$ centered around $x=0$.} pulse centered at $y=x$.
      This is exactly the idea of convolution.
      \begin{defn}
        \label{defn:convolution}
        Working formally, for two functions $f$ and $g$, the \emph{convolution} $f*g$ is the function
        \begin{align*}
          (f*g)(x) = \int_{-\infty}^\infty f(y)g(x-y)\,dy\text{.}
        \end{align*}
        By the change of variable $y\rightarrow x-y$
        \begin{align*}
          (f*g)(x) &= -\int_\infty^{-\infty} f(x-y)g(y)\,dy
          =(g*f)(x) \text{.}
        \end{align*}
      \end{defn}
      We think of the convolution of two functions at some point as an average, weighted by (a translated copy of) the other.
      \Cref{fig:convolve} shows an example of evaluating a convolution.

      The function $u(x,t)$ \cref{eq:heatsoln} is a convolution of the initial state $f(x)$ with a Gaussian pulse $e^{-(x-y)^2/4kt}$.
      As $t$ increases this pulse gets wider, reflecting the physical intuition of heat spreading out over time.

      \begin{figure}[p]
        \begin{center}
          \begin{sagesilent}
            from matplotlib import ticker
            x,y=var('x,y')
            z=1.6
            l,r=[.5,2.5]
            f = lambda x: (x^3+x^2-x+6)/10
            g = lambda j: lambda x: e^(-(j*x)^2)
            fg = lambda x: g(pi)(x-z)*(f(x)-1)
            a=plot(f(x)-1,x,[l,r],color="black",legend_label="$f(y)$")
            b=plot(g(pi)(x-z),x,[l,r],color=(.5,.5,.5),legend_label="$g(x-y)$")
            c = plot(fg,[l,r],color="grey",fill=true,ticks=[[z],[]],tick_formatter=ticker.FixedFormatter(['$x$']),axes_labels=['$y$',''],figsize=[6,4])
            d=a+b+c
            d.axes_range(l,r,-1/2,3/2)
            d.set_legend_options(loc='upper right')
          \end{sagesilent}
          \sageplot[width=\figwidth]{d}
          \vspace{-.5cm}
        \end{center}
        \caption{Evaluation of a convolution. The value $(f*g)(x)$ is given by the integral of the shaded area, the product of $f(y)$ with $g(x-y)$.}
        \label{fig:convolve}
      \end{figure}

    \section{Schwartz Functions}
      We hope to use \cref{lemma:fourprops} to find a space of functions that is closed under the Fourier transform, so that we may take Fourier transforms without concern, as we will always understand the result.

      Noting that $|\psi(x,\xi)|=1$ for all $x$ and $\xi$, we can see that the integral $\int_\xi f(\xi)\psi(x,\xi)\,d\xi$ will converge absolutely (and so will converge in \C) whenever $f$ is $L^1$-integrable---that is, when 
      \begin{align*}
        \int_{x\in\R} |f(x)|\,dx < \infty\text{.}
      \end{align*}
      Thus the Fourier transform is always defined for functions $f$ that \emph{vanish at infinity}\footnotemark and decay at least as fast as $x^{-2}$ (so $x^2f$ also vanishes at infinity), which are sufficient conditions for $L^1$-integrability.
      \footnotetext{
        That is, for any $\varepsilon>0$ there exists $N>0$ such that
        $ |x|>N \Longrightarrow f(x)<\epsilon\text{.} $
      }

      We also observed in \cref{ex:heateq} that the Fourier transform is useful because of its ability to exchange differentiation and multiplication.
      To make use of this fact, we also want our space to be closed when we take derivatives or multiply by $x$.
      This leaves us with the following requirements on our space of functions:
      \begin{enumerate}[label=(\alph*)]
        \item \label{i:vanish}Every function vanishes at infinity;
        \item \label{i:diff}It is closed under differentiation;
        \item \label{i:mult}It is closed under multiplication by $x$.
      \end{enumerate}
      We call such functions \emph{Schwartz functions}:

      \begin{defn}
        A Schwartz function is a function
        \begin{align*}
          \varphi:\R\rightarrow\C
        \end{align*}
        that is infinitely differentiable and is \emph{rapidly decaying}.
        That is, for any $k\ge0$, the derivative $\varphi^{(k)}$ decays faster than any power of $x$:
        \begin{align*}
          \forall d,k\ge0\ \ x^d\varphi^{(k)}(x)\text{ vanishes at infinity} \text{.}
        \end{align*}
        The set of all Schwartz functions is denoted \S.
      \end{defn}
      It is verifiable that \S is:
      \begin{itemize}
        \item the largest possible space satisfying the requirements above;
        \item a vectorspace over \C---that is, closed under addition and multiplication by complex numbers;
        \item closed under translation and multiplication by an oscillation;
        \item closed under differentiation and multiplication by $x$.
      \end{itemize}

      Because we made no reference to the Fourier transform in our definition of \S, the following bears proof:

      \begin{lemma}[Closure of \S under \F]
        \label{lemma:sclosed}
        Let $f\in\S$.
        Then $\F f\in\S$.
        \begin{proof}
          First, we can clearly see that $\F f$ is defined due to the decay condition on $f$.

          Now we wish to show that $\F f$ meets the decay condition for Schwartz functions.
          Applying integration by parts:
          \begin{align*}
            \xi^k\F f(\xi) &= \int_{x\in\R} f(x)\xi^ke^{-2\pi ix\xi}\,dx\\
            &= \left.f(x)\cdot\frac{\xi^{k-1}e^{-2\pi i x\xi}}{-2\pi i}\right|_{-\infty}^\infty - \frac{1}{-2\pi i}\int_{x\in\R} f'(x)\xi^{k-1}e^{-2\pi ix\xi}\,dx \text{.}
          \end{align*}
          Because $f$ is Schwartz, the left hand summand is clearly zero.
          Repeating this process $k$ times yields:
          \begin{align*}
            \xi^k\F f(\xi) &= \left(\frac{1}{2\pi i}\right)^k \int_{x\in\R}f^{(k)}(x)\overline\psi(x,\xi)\,dx \text{.}
          \end{align*}
          By definition $f^{(k)}$ is Schwartz, so we can apply the Riemann--Lebesgue Lemma and conclude $\lim_{|\xi|\rightarrow\infty} \xi^k\F f(\xi) = 0$, which is exactly the decay condition on Schwartz functions.

          Now we must show that $\F f$ is differentiable. 
          By \cref{eq:xisdiff} we see
          \begin{align*}
            (\F f)'(\xi) &= -2\pi i \F(\xi f)(\xi) \text{.}
          \end{align*}
          Because $\xi f$ is Schwartz by definition, we can see (from above) that $\F f$ is differentiable.
          In fact, $\F(\xi f)$, and thus $(\F f)'$, will decay faster than any power of $\xi$.
          Repeated applications of \cref{eq:xisdiff} will show this for all derivatives of $\F f$, and thus $\F f$ is Schwartz.
        \end{proof}
      \end{lemma}
      \begin{rmk}
        The proof of \cref{lemma:sclosed} relies on the (near-)symmetry of the Fourier transform with respect to differentiation and multiplication by $x$:
        \begin{itemize}
          \item $\F f$ decays faster than any power of $x$ because $f$ has infinitely many derivatives.
          \item $\F f$ has infinitely many derivatives because $f$ decays faster than any power of~$x$.
        \end{itemize}
      \end{rmk}

    \section{Fourier Inversion}
      Now that we have an appropriate environment, we can properly investigate the relationship we want to find between the normal and inverse Fourier transforms.
      \begin{thm}[Fourier Inversion on \S]
        \label{thm:fourinv}
        Let $\varphi$ be a Schwartz function.
        Then \[\F^{-1}\F \varphi = \varphi\text{.}\]
      \end{thm}
      To prove \cref{thm:fourinv} we first reduce it to the single case of $x=0$:
      \begin{claim}[Fourier inversion, granting inversion at 0]
        Suppose that for all\\$\phi\in\S$, $(\F^{-1}\F\phi)(0) = \phi(0)$.
        Then for all $\varphi\in\S$ and $x\in\R$, $(\F^{-1}\F\varphi)(x)=\varphi(x)$.
        \begin{proof}
          \begin{align*}
            (\F^{-1}\F\varphi)(x) &= (T_x\F^{-1}\F\varphi)(0) &\text{by defn. of $T_x$}\\
            &= (\F^{-1}(\psi_x\F\varphi))(0) &\text{by \cref{eq:tsltispsi}}\\
            &= (\F^{-1}\F T_x\varphi)(0)  &\text{by \cref{eq:tsltispsi2}}\\
            &= (T_x\varphi)(0) &\text{by hypothesis}\\
            &= \varphi(x)
          \end{align*}
        \end{proof}
      \end{claim}
      Thus we only need to show inversion at zero.

      \begin{rmk}
        The proof given here uses general properties of the Fourier Transform on~\R to normalize the problem, i.e., to reduce it to a convenient case.
        While Fourier inversion holds in general on $\R^n$, this proof only applies to the 1-dimensional case.
      \end{rmk}
      \begin{proof}[Proof of \cref{thm:fourinv}]
        We first reduce the problem further, using a trick with simple function:
        Recall that the \emph{Gaussian} function $\gamma:\R\rightarrow\R$ given by $\gamma(x) = e^{-\pi x^2}$ has $\gamma=\F\gamma=\F^{-1}\gamma$, and that (clearly) $\gamma(0)=1$.
        Then 
        \begin{align*}
          (\F^{-1}\F\varphi)(0) - \varphi(0) &= (\F^{-1}\F\varphi)(0) - (\varphi(0)\gamma)(0)\\
          &= (\F^{-1}\F\varphi - \varphi(0)\gamma)(0)\\
          &= (\F^{-1}\F\varphi - \varphi(0)(\F^{-1}\F\gamma))(0)\\
          &= \F^{-1}\F(\varphi-\varphi(0)\gamma)(0)
        \end{align*}
        using the linearity of $\F$ and $\F^{-1}$.
        Thus, because $(\varphi-\varphi(0)\gamma)(0)=0$, we need only show that $(\F^{-1}\F\phi)(0) = 0$ whenever $\phi(0)=0$.

        Having reduced the problem of Fourier inversion to the case where $x=0$ and our Schwartz function vanishes at zero, we suppose that $\phi\in\S$ satisfies $\phi(0)=0$. 
        Then for~$x\ne0$
        \begin{align*}
          \frac{\phi(x)}{x} = \frac{\phi(x)-\phi(0)}{x} = \int_{t=0}^1 \phi'(xt)dt \text{.}
        \end{align*}
        Call this integral $\varphi$.
        See that $\varphi$ is defined for \emph{all} $x$, which allows us to say that $\varphi(0)/0=\varphi'(0)$.
        We can easily calculate that $\varphi^{(k)}(x) = \int_0^1t^k\phi^{(k+1)}(xt)\,dt$, and so $\varphi$ and its derivatives will be smooth for all $x$ and will inherit rapid decay from $\phi$.
        Thus $\varphi\in\S$.

        By \cref{eq:xisdiff}:
        \begin{align*}
          (\F\phi)(\xi) = (\F x\varphi)(\xi)= -\frac{1}{2\pi i}(\F\varphi)'(\xi)
        \end{align*}
        and so we may calculate:
        \begin{align*}
          (\F^{-1}\F\phi)(0) = \int_{\xi\in\R} \F\phi(\xi)d\xi = -\frac{1}{2\pi i}\int_{\xi\in\R} (\F\varphi)'(\xi)d\xi = -\frac{1}{2\pi i} \F\varphi\vert_{-\infty}^\infty = 0
        \end{align*}
        thus proving Fourier inversion on \S.
      \end{proof}

    \section{Tempered Distributions}
      \label{sec:tempdist}
      We now want to consider Fourier inversion in the context of the \emph{continuous linear dual} of \S:
      \begin{align*}
        \S^* = \{f:\S\rightarrow\C\,\vert\,f\text{ is continuous and linear}\} \text{.}
      \end{align*}
      We call $\S^*$ the space of \emph{tempered distributions}.

      Note that we have not yet defined a notion of topology on \S, and so have no notion of continuity of functionals on \S, and so this definition is not yet exact.
      We will introduce a topology on \S in \cref{ch:topons}; until then we will not rely on topological notions.

      Schwartz functions naturally give rise to tempered distributions, so we have the inclusion:
      \begin{align*}
        \S\rightarrow\S^*\text{ by }\varphi \longmapsto\left(\phi\mapsto\int_{x\in\R}\varphi(x)\phi(x)dx\right) \text{.}
      \end{align*}
      For any $\varphi$ the integration-against functional is continuous; this will be clear after considering topology on \S.
      
      The inclusion allows us to define the Fourier transform for tempered distributions.
      For $f$ and $\varphi$ in \S, treat $f$ as a distribution:
      \begin{align*}
        \langle\F f,\varphi\rangle &= \int_\xi\F f(\xi)\varphi(\xi)\,d\xi\\
        &= \int_\xi\int_xf(x)\overline\psi(x,\xi)\,dx\,\varphi(\xi)\,d\xi\\
        &= \int_xf(x)\int_\xi\varphi(\xi)\overline\psi(x,\xi)\,d\xi dx\\
        &= \langle f,\F\varphi\rangle \text{.}
      \end{align*}
      We thus \emph{define} the Fourier transform of a \emph{general} $f\in\S^*$ by the adjoint-like characterization:
      \begin{align*}
        \langle\F f,\varphi\rangle = \langle f,\F\varphi\rangle\qquad\text{ for }f\in\S^*\text{ and }\varphi\in\S \text{.}
      \end{align*}
      We similarly define the inverse Fourier transform for $f\in\S^*$:
      \begin{align*}
        \langle\F^{-1}f,\varphi\rangle = \langle f,\F^{-1}\varphi\rangle\qquad\text{ for }\varphi\in\S \text{.}
      \end{align*}
      The key point is that these definitions are \emph{consistent} with our viewing Schwartz functions as tempered distributions---in fact, it is the only such way to define the Fourier transform on~$\S^*$.

      We would now like to show that the Fourier Transform on $\S^*$ behaves as nicely as it does on \S.
      Because we chose our definition to be consistent with viewing Schwartz functions as tempered distributions, much of this nice behavior is inherited.
      For example, the following result is basic, thanks to our definition.
      \begin{thm}[Fourier Inversion on $\S^*$]
        \label{thm:fourinv_td}
        Let $\varphi\in\S^*$.
        Then
        \begin{align*}
          \F^{-1}\F\varphi &= \varphi \text{.}
        \end{align*}
      \end{thm}
      \begin{proof}
        For $\phi\in\S$:
        \begin{align*}
          \langle\F^{-1}\F\varphi, \phi\rangle &= \langle \F\varphi, \F^{-1}\phi\rangle\\
          &= \langle\varphi, \F\F^{-1}\phi\rangle\\
          &= \langle\varphi, \phi\rangle
        \end{align*}
      \end{proof}

      In fact, similar (although admittedly less straightforward) proofs show all of the identities of \cref{lemma:fourprops} for tempered distributions.
      However, this undertaking also requires us to clarify just what is meant by the derivative of a tempered distribution, or multiplying a distribution by $x$.
      We will revisit these ideas when we have a more powerful set of (topological) tools at our disposal.
      We hope that by more closely examining \S and $\S^*$ we can discover what the answers \emph{must} be.
\end{document}
